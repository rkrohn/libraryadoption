import glob
import sys
import pandas as pd
import os
import pickle
from collections import defaultdict
from math import ceil
from datetime import timedelta
import numpy as np
from scipy import stats
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt

#given a filepath, load pickled data
def load_pickle(filename):
	with open(filename, "rb") as f:
		data = pickle.load(f)
	return data
#end load_pickle

#given a completed session as list of commit times and index of first adoption (if any),
#generate the pmf of the cpm rate on either side of the adoption event and plot
def session_commits(commit_times, first_adopt):	

	#normalize time scale, partition at adoption if necessary
	if NORM_TIME:
		#if session contains adoption, partition at 0
		if first_adopt != -1:
			#partition commit times at first adoption event
			pre_adopt = commit_times[:first_adopt+1]	#include adoption event here for now
			post_adopt = commit_times[first_adopt:]
			#normalize both sides separately, then combine
			relative_times = normalize(pre_adopt, -100, 0)[:-1]		#remove duplicate adoption event
			relative_times += normalize(post_adopt, 0, 100)
		#otherwise, take all commits at once
		else:
			relative_times = normalize(commit_times, 0, 100)
	#no normalization, just shift the UTC times (seconds) to minutes from some reference point
	else:
		#no adoption, shift times relative to first commit
		if first_adopt == -1:
			relative_times = [int((time - commit_times[0]) / (BIN_WIDTH * 60)) for time in commit_times]
		#adoption session, shift all times relative to first adoption event
		else:
			relative_times = [int((time - commit_times[first_adopt]) / (BIN_WIDTH * 60)) for time in commit_times]

	#build list of minute/percent counters covering entire range
	commit_bins = list(range(relative_times[0], relative_times[-1]+1))
	#and list of corresponding commit counts
	commit_counts = [0] * len(commit_bins)
	for time in relative_times:
		commit_counts[time + abs(relative_times[0])] += 1
	#multiply bins (times) by bin width to get back on the right scale
	commit_bins = [x * BIN_WIDTH for x in commit_bins]

	#return results
	return commit_bins, commit_counts
#end session_pmf

#for a completed session, log all session data
def log_session():
	#compute commit counts, shifted to either session start or first adoption, perhaps normalized
	times, commits = session_commits(session_commit_times, session_first_adopt)

	#add this session commit counts to overall session counters
	#also increment additive counter for all times covered by this session
	#adopt sessions
	if session_first_adopt != -1:
		for i in range(len(times)):
			total_adopt[times[i]] += commits[i]	
		for i in range(times[0], times[-1]+1):
			adopt_add[i] += 1	
	#non-adopt sessions
	else:
		for i in range(len(times)):
			total_non_adopt[times[i]] += commits[i]			
		for i in range(times[0], times[-1]+1):
			non_adopt_add[i] += 1

	#add this session data to global tracking
	len_bin = ceil(length / 1800) / 2		#compute half-hour bin for this session
#end log_session


#--- MAIN EXECUTION BEGINS HERE---#

max_inactive = 9 * 3600		#maximum time between commits of the same session (in seconds)

#flags and values to set operating mode
BIN_WIDTH = 5			#sets number of minutes per bin
PRE_WIN = 6 * 3600		#amount of time, in seconds, to include in the pre-commit activity window
POST_WIN = 6 * 3600		#time, in seconds, to include in post-commit activity window
AVG_ADOPT = 13.94559333795975	#average position of adoption commits within session as percentage
								#(generated by sessions_adopt.py)
POS_MARGIN = 0.1		#percent margin for either side of AVG_ADOPT - will only include non-adopt commits within
						#this window
ALL_MATCHING = True 	#if true, include all window-matching non-adopt commits in stack
						#if false, include a maximum of one non-adopt commit from each session (whichever is closest)

#get list of user commit files to process
files = glob.glob('data_files/user_commits/*')
print("Processing", len(files), "user commit files")

#global counters
total_commit_count = 0
total_adopt_commits = 0
total_user_count = 0
total_adopt_libs = 0
total_regular_commits = 0		#number of non-adopt commits stacked for comparison against adopt commits
								#(only commits that fall near AVG_ADOPT within their session)

#commit activity variables
adopt_activity_counts = defaultdict(int)	#key is minutes from adoption commit (pos or neg, in BIN_WIDTH increments)
											#value is # of commits made at that time (across all adopt commits by all users)
reg_activity_counts = defaultdict(int)		#same as above, but for regular non-adopt commits that fall at AVG_ADOPT
											#within their session, +/- POS_MARGIN

#process each file one at a time
for file in files:
	print("\nProcessing", file)

	user_commits = load_pickle(file)

	total_user_count += len(user_commits)

	#for each user in this chunk, step through their commits
	for user, commits in user_commits.items():

		#user variables
		prev = -1				#time of user's previous commit
		user_adopt_libs = 0		#number of libraries adopted by user
		user_adopt_commits = 0	#number of adoption commits by user

		#commit indices
		pre_start = 0			#index of first commit included in pre-commit activity window
		post_end = 0			#index of first commit excluded from post-commit activity window
		session_start = 0		#index of first commit in current session

		total_commit_count += len(commits)		#add users's commits to total count

		#loop all commits made by this user
		for i in range(0, len(commits)):

			#grab current commit for easier access
			c = commits[i]	

			#compute delay between this commit and the previous (if previous commit exists)
			if prev != -1:
				delay = c['time'] - prev
			else:
				delay = None
				session_start = i

			#delay too long, new session, process old session
			if delay != None and delay >= max_inactive:

				#pull start time of session and compute length of session
				start_time = commits[session_start]['time']
				length = prev - start_time

				#activity window boundaries (commit indices) for non-adopt commits
				non_pre_start = 0
				non_post_end = 0

				#track index of non-adopt commit closest to adoption time
				closest_loc = -1
				closest_dist = -1

				#find regular (non-adopt) commits that occur at around the same time/percent as the average adopt commit time
				for r_idx in range(session_start, i):
					#grab this regular commit r for easier access
					r = commits[r_idx]

					#skip this commit if adoption
					if r['adopted_libs']:
						continue

					#compute commit time/location as percentage of session length
					if length != 0:
						loc = ((r['time'] - start_time) / length) * 100
					else:
						loc = 0

					#if non-adopt commit and percent loc is close to avg adopt time, add to non-adopt activity total
					if loc < AVG_ADOPT + POS_MARGIN and loc > AVG_ADOPT - POS_MARGIN:

						#if stacking all non-adopt commits that fall within window, do that now
						if ALL_MATCHING:
							#find surrounding commits

							#move up pre_start index if necessary so that commit it points to falls within PRE_WIN
							while r['time'] - commits[non_pre_start]['time'] > PRE_WIN:
								non_pre_start += 1
							#move up post_end index if necessary so that commit it points to falls outside POST_WIN
							while non_post_end < len(commits) and commits[non_post_end]['time'] - r['time'] < POST_WIN:
								non_post_end += 1

							surrounding_commits = commits[non_pre_start:non_post_end]	#extract commits that fall within defined activity window

							#for each commit within activity window, compute "minutes from commit" and add to relevant bin counter
							for b in surrounding_commits:
								reg_activity_counts[int((b['time'] - r['time']) / (BIN_WIDTH * 60))* BIN_WIDTH] += 1
							total_regular_commits += 1

						#if not including all matching, only the closest, just keep track of the closest for now
						elif abs(loc - AVG_ADOPT) < closest_dist or closest_dist == -1:
							closest_dist = abs(loc - AVG_ADOPT)
							closest_loc = r_idx

				#if only taking closest commit from each session, stack that now
				if ALL_MATCHING == False and closest_loc != -1:
					#find surrounding commits of desired commit
					r = commits[closest_loc]	#grab commit for easier access
					non_pre_start = 0		#reset surrounding indices
					non_post_end = 0

					#move up pre_start index if necessary so that commit it points to falls within PRE_WIN
					while r['time'] - commits[non_pre_start]['time'] > PRE_WIN:
						non_pre_start += 1
					#move up post_end index if necessary so that commit it points to falls outside POST_WIN
					while non_post_end < len(commits) and commits[non_post_end]['time'] - r['time'] < POST_WIN:
						non_post_end += 1

					surrounding_commits = commits[non_pre_start:non_post_end]	#extract commits that fall within defined activity window

					#for each commit within activity window, compute "minutes from commit" and add to relevant bin counter
					for b in surrounding_commits:
						reg_activity_counts[int((b['time'] - r['time']) / (BIN_WIDTH * 60))* BIN_WIDTH] += 1
					total_regular_commits += 1

			#check if current commit contains an adoption, if so add to adoption stack
			if c['adopted_libs']:
				user_adopt_libs += len(c['adopted_libs'])	
				user_adopt_commits += 1	

				#move up pre_start index if necessary so that commit it points to falls within PRE_WIN
				while c['time'] - commits[pre_start]['time'] > PRE_WIN:
					pre_start += 1
				#move up post_end index if necessary so that commit it points to falls outside POST_WIN
				while post_end < len(commits) and commits[post_end]['time'] - c['time'] < POST_WIN:
					post_end += 1

				surrounding_commits = commits[pre_start:post_end]	#extract commits that fall within defined activity window

				#for each commit within activity window, compute "minutes from commit" and add to relevant bin counter
				for a in surrounding_commits:
					adopt_activity_counts[int((a['time'] - c['time']) / (BIN_WIDTH * 60))*BIN_WIDTH] += 1

			prev = c['time']	#update prev for next commit		

		#wrap up current user before moving to next
		print("User", user, "made", len(commits), "commits (" + str(user_adopt_commits), "adoption commits) adopting", user_adopt_libs, "libraries")		

		total_adopt_libs += user_adopt_libs
		total_adopt_commits += user_adopt_commits

	break
		

print("Processed", total_commit_count, "commits and", total_user_count, "users")
print("   ", total_adopt_libs, "libraries adopted in", total_adopt_commits, "adoption commits")

print("\nStacked", total_regular_commits, "non-adoption commits for comparison")

#tuple for output codes
out_tuple = (BIN_WIDTH, "ALL" if ALL_MATCHING else "CLOSEST")

#post-process totals for plotting
#get list of keys (times) that occur in either adopt or non-adopt activity dictionary
times = sorted(list(adopt_activity_counts.keys()) + list(set(reg_activity_counts.keys()) - set(adopt_activity_counts.keys())))

#divide adopt commits totals by total number of adoption commits (average), also convert to lists at the same time
#divide regular commit totals by number of regular commits stacked
adopt_activity_avg = []
non_adopt_activity_avg = []

for key in times:
	adopt_activity_avg.append(adopt_activity_counts[key] / total_adopt_commits)
	non_adopt_activity_avg.append(reg_activity_counts[key] / total_regular_commits)

#plot
plt.clf()
fig, ax = plt.subplots()
ax.plot(times, adopt_activity_avg, 'r', label='adoption commits')
ax.plot(times, non_adopt_activity_avg, 'b', label='non-adopt commits')
plt.legend(loc='best')
plt.axvline(x=0, color='k', lw=0.4)
plt.yscale('log')
plt.savefig("results/activity_analysis/commit_activity_%s_%s.png" % out_tuple, bbox_inches='tight')

print("Comarison plot saved to results/activity_analysis/commit_activity_%s_%s.png" % out_tuple)

#save adopt and non-adopt data to csv
col_header = "time_from_commit_(minutes)"
np.savetxt("results/activity_analysis/commit_activity_data_%s_%s.csv" % out_tuple, np.column_stack(([col_header] + times, ['adopt_activity'] + non_adopt_activity_avg, ['non_adopt_activity'] + non_adopt_activity_avg)), delimiter=",", fmt="%s")