Using features [29 30 31 32 33 34 35 36 37 38 39] 

Testing 2 classifier configurations

TRAINING DATA:
Loading events for 2004, months 1-12
Loading events for 2005, months 1-12
Replacing nan with 0
Using MinMaxScaler for normalization
read 5026640 import training events with 11 features
    5642 events are adoptions

TESTING DATA:
Loading events for 2006, month 1
Replacing nan with 0
read 425190 testing events with 11 features
    745 events are adoptions


TEST 0 {'penalty': 'l2', 'loss': 'squared_hinge', 'shuffle': True, 'fit_intercept': True}
Training classifier...
SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,
       eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=50, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False) 


coefficients: [[-1384837.05690759   317461.17348375   889308.4634534   -926652.84034297
    950756.73981162 -2557089.05500425 -5612412.55536459    24967.39475562
     14529.45709625    37697.84930024  -181611.7878228 ]]
intercept: [-16808.61038964] 

745 adoption events in 425190 import events
predicted 2321 adoptions

true pos: 3
true neg: 422127
false pos: 2318
false neg: 742 

precision: 0.0012925463162429987
recall: 0.004026845637583893
F-1 score: 0.0019569471624266144
AUROC score: 0.4992827981206567

TEST 1 {'penalty': 'l1', 'loss': 'squared_hinge', 'shuffle': True, 'fit_intercept': False}
Training classifier...
SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,
       eta0=0.0, fit_intercept=False, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=50, n_jobs=1,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False) 


coefficients: [[ 12.22719686   6.09278606   0.         -40.02115802  11.79217342
  -17.29383369 -48.48158097   0.          -8.2223868  -16.04775304
   -4.43847763]]
intercept: [0.] 

745 adoption events in 425190 import events
predicted 2926 adoptions

true pos: 5
true neg: 421524
false pos: 2921
false neg: 740 

precision: 0.0017088174982911825
recall: 0.006711409395973154
F-1 score: 0.002724053391446472
AUROC score: 0.49991474061547886

All results saved to predict_tests/newest_results_2018-07-12_14:39:00.csv
